在PC机中,由于早期版本的系统资源限制,其物理内存被分为多个不同的区域,并一直延续至今,那么QEMU是如何对这种静态内存布局进行模拟的呢？

## 1.1 整体内存分配

虽然PC机的物理内存被人为地分为多个不同的区域,但是在物理结构上它们仍然是连续的,因此qemu直接从宿主机中分配了一块内存:

```c
// exec.c
uint8_t *phys_ram_base; /* 物理内存块的首地址(宿主机实际的内存地址) */

// vl.c
int main(int argc, char **argv, char **envp)
{
	//...
     /* init the memory */
     phys_ram_size = machine->ram_require & ~RAMSIZE_FIXED;
     if (machine->ram_require & RAMSIZE_FIXED) {
         if (ram_size > 0) {
              if (ram_size < phys_ram_size) {
                   fprintf(stderr, "Machine `%s' requires %llu bytes of memory/n",
                       machine->name, (unsigned long long) phys_ram_size);
                   exit(-1);
              }
              phys_ram_size = ram_size;
         } else
              ram_size = phys_ram_size;
     } else {
         if (ram_size == 0)
              ram_size = DEFAULT_RAM_SIZE * 1024 * 1024;
         phys_ram_size += ram_size;
     }
     phys_ram_base = qemu_vmalloc(phys_ram_size); /* 这里返回的是宿主机上实际的内存地址 */
     if (!phys_ram_base) {
         fprintf(stderr, "Could not allocate physical memory/n");
         exit(1);
     }
	//...
    return 0;
}
```

在这一段代码里面,ram_size变量的值可以通过"-m megs"参数指定,如果没指定则取默认值 DEFAULT_RAM_SIZE,即:

```c
#define DEFAULT_RAM_SIZE 128
```

但总共分配的内存并不只这些,还要加上 machine->ram_require的大小,这个值来自于预定义的常量,对于pc模拟而言就是:

```c
QEMUMachine pc_machine = {
    .name = "pc",
    .desc = "Standard PC",
    .init = pc_init_pci,
    .ram_require = VGA_RAM_SIZE + PC_MAX_BIOS_SIZE,
    .max_cpus = 255,
};
```

也就是说,总共分配的内存还要加上VGA_RAM_SIZE 和 PC_MAX_BIOS_SIZE:

```c
#define VGA_RAM_SIZE (8192 * 1024)
#define PC_MAX_BIOS_SIZE (4 * 1024 * 1024)
```

总共12M.

在分配了内存后,将其指针保存在phys_ram_base这一全局变量中,猜测以后虚拟机访问SDRAM的操作都将访问此内存块.


## 1.2 内存块的再分配

如果要从前面分配的大内存块中取一小块,则必须使用 `qemu_ram_alloc` 函数:

```c
// exec.c
static ram_addr_t phys_ram_alloc_offset = 0; /* 记录未使用的物理内存块的偏移,物理内存块的首地址记录在phys_ram_base之中 */

/* XXX: better than nothing */
ram_addr_t qemu_ram_alloc(ram_addr_t size)
{
    ram_addr_t addr;
    if ((phys_ram_alloc_offset + size) > phys_ram_size) {
        fprintf(stderr, "Not enough memory (requested_size = %" PRIu64 ", max memory = %" PRIu64 ")\n",
                (uint64_t)size, (uint64_t)phys_ram_size);
        abort();
    }
    addr = phys_ram_alloc_offset;
    phys_ram_alloc_offset = TARGET_PAGE_ALIGN(phys_ram_alloc_offset + size);

    if (kvm_enabled())
        kvm_setup_guest_memory(phys_ram_base + addr, size);

    return addr;
}
```

从这个函数可以看出,它使用了按顺序从低到高分配这种很简单的手段,用phys_ram_alloc_offset这一个全局变量记录当前已经分配了多少内存.

需要注意的是,这个函数最后返回的也是一个偏移量,而不是宿主机上的实际内存地址.

## 1.3 内存块管理

对于使用 `qemu_ram_alloc` 分配出来的内存块,通常还需要调用 `cpu_register_physical_memory` 进行注册:

```c
// cpu-all.h
static inline void cpu_register_physical_memory(target_phys_addr_t start_addr,
                                                ram_addr_t size,
                                                ram_addr_t phys_offset)
{
    cpu_register_physical_memory_offset(start_addr, size, phys_offset, 0);
}

/* register physical memory. 'size' must be a multiple of the target
   page size. If (phys_offset & ~TARGET_PAGE_MASK) != 0, then it is an
   io memory page.  The address used when calling the IO function is
   the offset from the start of the region, plus region_offset.  Both
   start_region and regon_offset are rounded down to a page boundary
   before calculating this offset.  This should not be a problem unless
   the low bits of start_addr and region_offset differ.  */
void cpu_register_physical_memory_offset(target_phys_addr_t start_addr,
                                         ram_addr_t size,
                                         ram_addr_t phys_offset,
                                         ram_addr_t region_offset)
{
    target_phys_addr_t addr, end_addr;
    PhysPageDesc *p;
    CPUState *env;
    ram_addr_t orig_size = size;
    void *subpage;

	// ...
    region_offset &= TARGET_PAGE_MASK;
    size = (size + TARGET_PAGE_SIZE - 1) & TARGET_PAGE_MASK;
    end_addr = start_addr + (target_phys_addr_t)size;
    for(addr = start_addr; addr != end_addr; addr += TARGET_PAGE_SIZE) {
        p = phys_page_find(addr >> TARGET_PAGE_BITS);
        if (p && p->phys_offset != IO_MEM_UNASSIGNED) {
 			// ...
        } else {
            p = phys_page_find_alloc(addr >> TARGET_PAGE_BITS, 1); /* 分配一个物理页描述符 */
            p->phys_offset = phys_offset;
            p->region_offset = region_offset;
            if ((phys_offset & ~TARGET_PAGE_MASK) <= IO_MEM_ROM ||
                (phys_offset & IO_MEM_ROMD)) {
                phys_offset += TARGET_PAGE_SIZE;
            } else {
               // ...
            }
        }
        region_offset += TARGET_PAGE_SIZE;
    }

    /* since each CPU stores ram addresses in its TLB cache, we must
       reset the modified entries */
    /* XXX: slow ! */
    for(env = first_cpu; env != NULL; env = env->next_cpu) {
        tlb_flush(env, 1);
    }
}
```

从这段代码可以猜测到,QEMU对每一个注册进来的内存块都进行了分页,每一个页面大小为4K,且用一个结构体对这些页进行描述:

```c
// exec.c
typedef struct PhysPageDesc {
    /* offset in host memory of the page + io_index in the low bits */
    ram_addr_t phys_offset;
    ram_addr_t region_offset;
} PhysPageDesc;
```

然后采用某种机制对此结构体的变量进行管理.在这个结构体里的phys_offset指出这个页面的实际内容存放的位置,通过这个偏移量和phys_ram_base可以访问到这个页面的实际内容,也是通过这个手段实现了对bios内容的映射.而region_offset则指出这个内存页在其所属的内存块中的偏移量,其数值为4K的整数倍.

## 1.4 对PC静态内存布局的模拟
在QEMU启动对X86结构的模拟时,会调用一个叫pc_init1的函数:

```c
/* PC hardware initialisation */
static void pc_init1(ram_addr_t ram_size, int vga_ram_size,
                     const char *boot_device,
                     const char *kernel_filename, const char *kernel_cmdline,
                     const char *initrd_filename,
                     int pci_enabled, const char *cpu_model)
{
    char buf[1024];
    int ret, linux_boot, i;
    ram_addr_t ram_addr, vga_ram_addr, bios_offset, vga_bios_offset;
    ram_addr_t below_4g_mem_size, above_4g_mem_size = 0;
    int bios_size, isa_bios_size, vga_bios_size;
    PCIBus *pci_bus;
    int piix3_devfn = -1;
    CPUState *env;
    qemu_irq *cpu_irq;
    qemu_irq *i8259;
    int index;

	// ...
    /* allocate RAM */
    ram_addr = qemu_ram_alloc(0xa0000); /* 640KB的常规内存 */
    cpu_register_physical_memory(0, 0xa0000, ram_addr); /* 00000h ~ 9ffffh */

    /* Allocate, even though we won't register, so we don't break the
     * phys_ram_base + PA assumption. This range includes vga (0xa0000 - 0xc0000),
     * and some bios areas, which will be registered later
     */
    ram_addr = qemu_ram_alloc(0x100000 - 0xa0000); /* 384KB的上位内存区 */
    ram_addr = qemu_ram_alloc(below_4g_mem_size - 0x100000);
    cpu_register_physical_memory(0x100000,
                 below_4g_mem_size - 0x100000,
                 ram_addr);

    /* above 4giga memory allocation */
    if (above_4g_mem_size > 0) {
        ram_addr = qemu_ram_alloc(above_4g_mem_size); /* 扩展内存区域 */
        cpu_register_physical_memory(0x100000000ULL,
                                     above_4g_mem_size,
                                     ram_addr);
    }

    /* allocate VGA RAM */
    vga_ram_addr = qemu_ram_alloc(vga_ram_size);

    /* BIOS load */
    if (bios_name == NULL)
        bios_name = BIOS_FILENAME;
    snprintf(buf, sizeof(buf), "%s/%s", bios_dir, bios_name); /* bios的存放路径 */
    bios_size = get_image_size(buf);
    if (bios_size <= 0 ||
        (bios_size % 65536) != 0) {
        goto bios_error;
    }
    bios_offset = qemu_ram_alloc(bios_size);
    ret = load_image(buf, phys_ram_base + bios_offset); /* 加载bios镜像到phys_ram_base + bios_offset的位置 */
    if (ret != bios_size) {
    bios_error:
        fprintf(stderr, "qemu: could not load PC BIOS '%s'\n", buf);
        exit(1);
    }

    if (cirrus_vga_enabled || std_vga_enabled || vmsvga_enabled) {
        /* VGA BIOS load */
        if (cirrus_vga_enabled) {
            snprintf(buf, sizeof(buf), "%s/%s", bios_dir, VGABIOS_CIRRUS_FILENAME);
        } else {
            snprintf(buf, sizeof(buf), "%s/%s", bios_dir, VGABIOS_FILENAME);
        }
        vga_bios_size = get_image_size(buf);
        if (vga_bios_size <= 0 || vga_bios_size > 65536)
            goto vga_bios_error;
        vga_bios_offset = qemu_ram_alloc(65536);

        ret = load_image(buf, phys_ram_base + vga_bios_offset);
        if (ret != vga_bios_size) {
vga_bios_error:
            fprintf(stderr, "qemu: could not load VGA BIOS '%s'\n", buf);
            exit(1);
        }

        /* setup basic memory access */
        cpu_register_physical_memory(0xc0000, 0x10000,
                                     vga_bios_offset | IO_MEM_ROM);
    }

    /* map the last 128KB of the BIOS in ISA space */
    isa_bios_size = bios_size;
    if (isa_bios_size > (128 * 1024))
        isa_bios_size = 128 * 1024;
    cpu_register_physical_memory(0x100000 - isa_bios_size,
                                 isa_bios_size,
                                 (bios_offset + bios_size - isa_bios_size) | IO_MEM_ROM);

 	// ...

    /* map all the bios at the top of memory */
    cpu_register_physical_memory((uint32_t)(-bios_size),
                                 bios_size, bios_offset | IO_MEM_ROM);
	// ...
}
```

这段代码按从低到高的顺序依次注册了几个内存块:

+ 常规内存(Conventional Memory):系统内存的第一个640 KB就是著名的常规内存.它是标准DOS程序、DOS驱动程序、常驻内存程序等可用的区域,它们统统都被放置在00000h~9FFFFh之间.
+ 上位内存区(Upper Memory Area):系统内存的第一个1M内存顶端的384 KB(1024 KB - 640 KB)就是UMA,它紧随在常规内存之后.也就是说,第一个1M内存被分成640KB常规内存和384KB的UMA.这个区域是系统保留区域,用户程序不能使用它.它一部分被系统设备(CGA、VGA等)使用,另外一部分被用做ROM shadowing和Drivers.UMA使用内存区域A0000h~FFFFFh.
+ 扩展内存(Extended Memory) 从0x100000到系统物理内存的最大值之间的区域都属于扩展内存.当一个OS运行在Protected Mode时,它可以被访问,而在Real Mode下,则无法被访问*(*除非通过某些*Hacker*方法*)*.

本来扩展内存的第一个64K可以独立出来称之为HMA,但是从上面的代码可以看到,QEMU并没有将之单独列出来.

紧接着要模拟的物理内存之后,QEMU分配了8M的显存.

在显存之后,分配了一块空间给bios,而这段空间的内容则直接来自于bios.bin这一文件,QEMU提供的bios.bin大小为128K.

在bios之后,分配了64K的空间给vga bios,而这段的内容则来自于vgabios-cirrus.bin文件.

## 1.5 内存的访问

一般而言,cpu之中,存在有两类地址,一类是IO地址,cpu通过对IO地址的读/写,完成对硬件的控制.

另外一类地址,就是普通的内存地址,用途是简单的读写数据.

### IO地址

qemu所模拟的硬件,一般都会调用register_ioport_write, register_ioport_read之类的函数来注册io端口读写函数,比如说pci接口:

```c
// piix_pic.c
PCIBus *i440fx_init(PCIDevice **pi440fx_state, qemu_irq *pic)
{
    // ...
    register_ioport_write(0xcf8, 4, 4, i440fx_addr_writel, s);
    register_ioport_read(0xcf8, 4, 4, i440fx_addr_readl, s);
    //...
}
```

register_ioport_write用于注册写回调.register_ioport_read用于注册读回调.

```c
// vl.c
static void *ioport_opaque[MAX_IOPORTS];
static IOPortReadFunc *ioport_read_table[3][MAX_IOPORTS]; /* 记录io读回调 */
static IOPortWriteFunc *ioport_write_table[3][MAX_IOPORTS]; /* 记录io写回调 */

/* 注册io写回调函数
 * @param start 物理地址
 * @param length 长度
 * @param size 要写数据的大小
 * @param func 回调函数
 * @param opaque 将会传递给回调函数的私有数据
 */
int register_ioport_write(int start, int length, int size,
                          IOPortWriteFunc *func, void *opaque)
{
    int i, bsize;

    if (size == 1) {
        bsize = 0;
    } else if (size == 2) {
        bsize = 1;
    } else if (size == 4) {
        bsize = 2;
    } else {
        hw_error("register_ioport_write: invalid size");
        return -1;
    }
    for(i = start; i < start + length; i += size) {
        ioport_write_table[bsize][i] = func;
        if (ioport_opaque[i] != NULL && ioport_opaque[i] != opaque)
            hw_error("register_ioport_write: invalid opaque");
        ioport_opaque[i] = opaque;
    }
    return 0;
}

/* size is the word size in byte */
/* 注册io读函数 */
int register_ioport_read(int start, int length, int size,
                         IOPortReadFunc *func, void *opaque)
{
    int i, bsize;

    if (size == 1) {
        bsize = 0;
    } else if (size == 2) {
        bsize = 1;
    } else if (size == 4) {
        bsize = 2;
    } else {
        hw_error("register_ioport_read: invalid size");
        return -1;
    }
    for(i = start; i < start + length; i += size) {
        ioport_read_table[bsize][i] = func;
        if (ioport_opaque[i] != NULL && ioport_opaque[i] != opaque)
            hw_error("register_ioport_read: invalid opaque");
        ioport_opaque[i] = opaque;
    }
    return 0;
}
```

我们以cpu读取1个字节的数据,来追踪一下,cpu是如何从对应io端口读数据的,cpu通过port之类的汇编指令,最终会调度到helper_inb函数.这个函数会一路调度到ioport_read,在这个函数中,会调用之前硬件注册的io读回调函数,从而将数据读取出来.

```c
// vl.c
/* 执行io读操作
 * @param index 要读取的数据的宽度,0表示byte, 1表示word,2表示long
 * @param address 要读取的地址
 */
static uint32_t ioport_read(int index, uint32_t address)
{
    static IOPortReadFunc *default_func[3] = {
        default_ioport_readb,
        default_ioport_readw,
        default_ioport_readl
    };
    IOPortReadFunc *func = ioport_read_table[index][address];
    if (!func)
        func = default_func[index];
    return func(ioport_opaque[address], address);
}

int cpu_inb(CPUState *env, int addr)
{
    int val;
    val = ioport_read(0, addr); /* 读取一个字节的数据 */
    LOG_IOPORT("inb : %04x %02x\n", addr, val);
    return val;
}

// op_helper.c
target_ulong helper_inb(uint32_t port)
{
    return cpu_inb(env, port);
}
```

如果cpu想写1个字节数据到指定的io端口去,会通过port汇编指令,最终会调度到helper_outb.然后一路调度到io_port_write,在这个函数中,会调用之前硬件注册的io写回调函数,从而将数据写进去.

```c
/* 执行io写操作
 * @param address 需要写入的地址
 * @param data 需要写入的数据
 * @param index 用于指示写入数据的宽度,0表示byte, 1表示word,2表示long
 */
static void ioport_write(int index, uint32_t address, uint32_t data)
{
    static IOPortWriteFunc *default_func[3] = { /* 默认写函数 */
        default_ioport_writeb,
        default_ioport_writew,
        default_ioport_writel
    };
    IOPortWriteFunc *func = ioport_write_table[index][address];
    if (!func)
        func = default_func[index];
    func(ioport_opaque[address], address, data);
}

void cpu_outb(CPUState *env, int addr, int val)
{
    LOG_IOPORT("outb: %04x %02x\n", addr, val);
    ioport_write(0, addr, val); /* cpu进行io写操作 */
}

// op_helper.c
void helper_outb(uint32_t port, uint32_t data)
{
    cpu_outb(env, port, data & 0xff);
}
```

### 内存地址

访问内存地址,自然要通过store/load之类的汇编指令.这类指令一般使用的是线性地址,线性地址到实际物理地址的转换,需要通过mmu,这里的过程实际非常复杂,具体流程可以参考本人在阅读qemu v0.4.4时所记录的笔记--<<qemu softmmu浅析>>. v0.10.6虽然代码有所变动,但是思想并未发生改变.

————————————————
版权声明:本文为CSDN博主「嵌云阁主」的原创文章,遵循CC 4.0 BY-SA版权协议,转载请附上原文出处链接及本声明.
原文链接:https://blog.csdn.net/lights_joy/article/details/4354238
